<!doctype html><html lang=zh-hans><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Source Themes Academic 4.3.1"><meta name=author content="天师大 iOS 社团"><meta name=description content="Oral paper on INTERSPEECH 2018."><link rel=alternate hreflang=en href=/accomplishment/zhaoyiqin-pub-exploringst/><link rel=alternate hreflang=zh-hans href=/zh/accomplishment/zhaoyiqin-pub-exploringst/><meta name=theme-color content="#2962ff"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin=anonymous><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.6.0/css/all.css integrity=sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css crossorigin=anonymous title=hl-light><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css crossorigin=anonymous title=hl-dark disabled><link rel=stylesheet href="//fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono"><link rel=stylesheet href=/css/academic.min.a0cd2c630ba7432a1a4a8a86bf0e6db4.css><link rel=manifest href=/site.webmanifest><link rel=icon type=image/png href=/img/icon.png><link rel=apple-touch-icon type=image/png href=/img/icon-192.png><link rel=canonical href=/zh/accomplishment/zhaoyiqin-pub-exploringst/><meta property="twitter:card" content="summary"><meta property="og:site_name" content="TJNU-iOS-Club"><meta property="og:url" content="/zh/accomplishment/zhaoyiqin-pub-exploringst/"><meta property="og:title" content="[Publication] Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition | TJNU-iOS-Club"><meta property="og:description" content="Oral paper on INTERSPEECH 2018."><meta property="og:image" content="/img/icon-192.png"><meta property="og:locale" content="zh-Hans"><meta property="article:published_time" content="2018-03-28T00:00:00+00:00"><meta property="article:modified_time" content="2018-03-28T00:00:00+00:00"><title>[Publication] Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition | TJNU-iOS-Club</title></head><body id=top data-spy=scroll data-target=#TableOfContents data-offset=71><aside class=search-results id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>搜索</h1></div><div class="col-6 col-search-close"><a class=js-search href=#><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=搜索... autocapitalize=off autocomplete=off autocorrect=off role=textbox spellcheck=false type=search></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id=navbar-main><div class=container><a class=navbar-brand href=/zh>TJNU-iOS-Club</a>
<button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar aria-controls=navbar aria-expanded=false aria-label=切换导航>
<span><i class="fas fa-bars"></i></span></button><div class="collapse navbar-collapse" id=navbar><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/zh/#about><span>主页</span></a></li><li class=nav-item><a class=nav-link href=/zh/#activities><span>活动</span></a></li><li class=nav-item><a class=nav-link href=/zh/#member><span>成员</span></a></li><li class=nav-item><a class=nav-link href=/zh/#history><span>历史</span></a></li><li class=nav-item><a class=nav-link href=/zh/#acc><span>成果</span></a></li><li class=nav-item><a class=nav-link href=/zh/#posts><span>文章</span></a></li><li class=nav-item><a class=nav-link href=/zh/#contact><span>联系我们</span></a></li><li class=nav-item><a class=nav-link href=/zh/#links><span>相关链接</span></a></li></ul><ul class="navbar-nav ml-auto"><li class=nav-item><a class="nav-link js-search" href=#><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><i class="fas fa-globe" aria-hidden=true></i><span>中文 (简体)</span></a><ul class=dropdown-menu><li class="dropdown-item my-0 py-0 mx-0 px-0"><a href=/accomplishment/zhaoyiqin-pub-exploringst/><span>English</span></a></li></ul></li><li class=nav-item><a class="nav-link js-dark-toggle" href=#><i class="fas fa-moon" aria-hidden=true></i></a></li></ul></div></div></nav><article class=article itemscope itemtype=http://schema.org/Article><div class="article-container pt-3"><h1 itemprop=name>[Publication] Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition</h1><meta content="2018-03-28 00:00:00 +0000 +0000" itemprop=datePublished><meta content="2018-03-28 00:00:00 +0000 +0000" itemprop=dateModified><div class=article-metadata><div><span itemprop="author name" itemtype=http://schema.org/Person><a href=/zh/authors/zhaoyiqin/>赵一勤</a></span></div><span class=article-date><time>2018-03-28</time></span><div class=share-box aria-hidden=true><ul class=share><li><a class=twitter href="https://twitter.com/intent/tweet?text=&url=" target=_blank rel=noopener><i class="fab fa-twitter"></i></a></li><li><a class=facebook href="https://www.facebook.com/sharer.php?u=" target=_blank rel=noopener><i class="fab fa-facebook-f"></i></a></li><li><a class=linkedin href="https://www.linkedin.com/shareArticle?mini=true&url=&title=" target=_blank rel=noopener><i class="fab fa-linkedin-in"></i></a></li><li><a class=weibo href="http://service.weibo.com/share/share.php?url=&title=" target=_blank rel=noopener><i class="fab fa-weibo"></i></a></li><li><a class=email href="mailto:?subject=&body="><i class="fas fa-envelope"></i></a></li></ul></div></div></div><div class=article-container><div class=article-style itemprop=articleBody><p><a href=https://www.isca-speech.org/archive/Interspeech_2018/pdfs/1477.pdf>PDF</a></p><h1 id=abstract>Abstract</h1><p>Automatic emotion recognition from speech, which is an important and challenging task in the field of affective computing, heavily relies on the effectiveness of the speech features for classification. Previous approaches to emotion recognition have mostly focused on the extraction of carefully hand-crafted features. How to model spatio-temporal dynamics for speech emotion recognition effectively is still under active investigation. In this paper, we propose a method to tackle the problem of emotional relevant feature extraction from speech by leveraging Attention-based Bidirectional Long Short-Term Memory Recurrent Neural Networks with fully convolutional networks in order to automatically learn the best spatio-temporal representations of speech signals. The learned high-level features are then fed into a deep neural network (DNN) to predict the final emotion. The experimental results on the Chinese Natural Audio-Visual Emotion Database (CHEAVD) and the Interactive Emotional Dyadic Motion Capture (IEMOCAP) corpora show that our method provides more accurate predictions compared with other existing emotion recognition algorithms.</p><h1 id=cite>Cite</h1><pre><code>@inproceedings{Zhao2018,
  author={Ziping Zhao and Yu Zheng and Zixing Zhang and Haishuai Wang and Yiqin Zhao and Chao Li},
  title={Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition},
  year=2018,
  booktitle={Proc. Interspeech 2018},
  pages={272--276},
  doi={10.21437/Interspeech.2018-1477},
  url={http://dx.doi.org/10.21437/Interspeech.2018-1477}
}
</code></pre></div><div class=article-tags><a class="badge badge-light" href=/zh/tags/publication/>Publication</a>
<a class="badge badge-light" href=/zh/tags/affective-computing/>Affective Computing</a></div><div class="media author-card" itemscope itemtype=http://schema.org/Person><img class="portrait mr-3" src=/zh/authors/zhaoyiqin/avatar_hudd0b8b129a084ca22426b987e0cc5b77_23906_250x250_fill_q90_lanczos_center.jpg itemprop=image alt=Avatar><div class=media-body><h5 class=card-title itemprop=name><a href=/zh/authors/zhaoyiqin/>赵一勤</a></h5><h6 class=card-subtitle>2019 届</h6><p class=card-text itemprop=description>天津师范大学2015级软件工程本科生，主要研究方向：情感计算，机器学习。</p><ul class=network-icon aria-hidden=true><li><a itemprop=sameAs href=https://yiqinzhao.me target=_blank rel=noopener><i class="fas fa-home"></i></a></li><li><a itemprop=sameAs href=https://weibo.com/2394512141/profile target=_blank rel=noopener><i class="fab fa-weibo"></i></a></li></ul></div></div><div id=gitalk-container></div><script src=https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css><script src=https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js></script><script>const gitalk=new Gitalk({clientID:'5372b71f251af871c618',clientSecret:'d6fd040045363d30087917e05a476c981613ba5a',repo:'TJNU-iOS-Club.github.io',owner:'TJNU-iOS-Club',admin:["YiqinZhao","KimYangOfCat","godjiawen"],labels:['Comments'],id:md5(location.pathname),distractionFreeMode:false,language:'zh-CN',perPage:10,distractionFreeMode:false,createIssueManually:false,});(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('gitalk-container').innerHTML='Gitalk comments not available by default when the website is previewed locally.Gitalk 评论系统不能在本地预览效果！';return;}
gitalk.render('gitalk-container');})();</script></div></article><div class=container><footer class=site-footer><p class=powered-by>TJNU-iOS-Club © 2020 &#183;
Powered by the
<a href=https://sourcethemes.com/academic/ target=_blank rel=noopener>Academic theme</a> for
<a href=https://gohugo.io target=_blank rel=noopener>Hugo</a>.
<span class=float-right aria-hidden=true><a href=# id=back_to_top><span class=button_icon><i class="fas fa-chevron-up fa-2x"></i></span></a></span></p></footer></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>引用</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i>复制</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i>下载</a><div id=modal-error></div></div></div></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin=anonymous></script><script>hljs.initHighlightingOnLoad();</script><script>const search_index_filename="/zh/index.json";const i18n={'placeholder':"搜索...",'results':"搜索结果",'no_results':"没有找到结果"};const content_type={'post':"文章",'project':"项目",'publication':"出版物",'talk':"演讲"};</script><script id=search-hit-fuse-template type=text/x-template>
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script><script src=/js/academic.min.c0da55633859d3dfa3c3052483e35fb5.js></script></body></html>